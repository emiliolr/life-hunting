{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ccc35ff-7297-4057-96ef-9dc1333bc4c8",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08676b88-b0cc-4164-b261-269c24cacf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from pymer4 import Lmer\n",
    "from flaml import AutoML\n",
    "\n",
    "from utils import read_csv_non_utf, preprocess_data, get_zero_nonzero_datasets, test_thresholds, ratios_to_DI_cats\n",
    "from model_utils import HurdleModelEstimator, PymerModelWrapper\n",
    "from custom_metrics import balanced_accuracy_FLAML, mean_absolute_error_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dd025bc-f9fb-4b3a-b8f9-880619219724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in general configuration\n",
    "with open('../config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Getting filepaths\n",
    "gdrive_fp = config['gdrive_path']\n",
    "LIFE_fp = config['LIFE_folder']\n",
    "dataset_fp = config['datasets_path']\n",
    "benitez_lopez2019 = config['indiv_data_paths']['benitez_lopez2019']\n",
    "ferreiro_arias2024 = config['indiv_data_paths']['ferreiro_arias2024']\n",
    "\n",
    "ben_lop_path = os.path.join(gdrive_fp, LIFE_fp, dataset_fp, benitez_lopez2019)\n",
    "fer_ari_path = os.path.join(gdrive_fp, LIFE_fp, dataset_fp, ferreiro_arias2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e52eb47-8914-4a9a-844f-7fa898e6c76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>Species</th>\n",
       "      <th>BirdLife_Species</th>\n",
       "      <th>BirdTree_Species</th>\n",
       "      <th>IUCN_Species</th>\n",
       "      <th>Hunting</th>\n",
       "      <th>...</th>\n",
       "      <th>TravDist</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>Stunting</th>\n",
       "      <th>FoodBiomass</th>\n",
       "      <th>Reserve</th>\n",
       "      <th>Forest_cover</th>\n",
       "      <th>NPP</th>\n",
       "      <th>CountryNum</th>\n",
       "      <th>Food</th>\n",
       "      <th>Hunted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>Galliformes</td>\n",
       "      <td>Cracidae</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.695656</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>76</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>Galliformes</td>\n",
       "      <td>Cracidae</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.695656</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>76</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>Galliformes</td>\n",
       "      <td>Cracidae</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.695656</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>76</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>Galliformes</td>\n",
       "      <td>Cracidae</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.695656</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>76</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>442</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>Galliformes</td>\n",
       "      <td>Cracidae</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>Mitu tuberosum</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>17.695656</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>76</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Study  Dataset Reviewer        Order    Family         Species  \\\n",
       "0   442        9       AB  Galliformes  Cracidae  Mitu tuberosum   \n",
       "1   442        9       AB  Galliformes  Cracidae  Mitu tuberosum   \n",
       "2   442        9       AB  Galliformes  Cracidae  Mitu tuberosum   \n",
       "3   442        9       AB  Galliformes  Cracidae  Mitu tuberosum   \n",
       "4   442        9       AB  Galliformes  Cracidae  Mitu tuberosum   \n",
       "\n",
       "  BirdLife_Species BirdTree_Species    IUCN_Species Hunting  ...  TravDist  \\\n",
       "0   Mitu tuberosum   Mitu tuberosum  Mitu tuberosum       S  ...    2389.0   \n",
       "1   Mitu tuberosum   Mitu tuberosum  Mitu tuberosum       S  ...    2389.0   \n",
       "2   Mitu tuberosum   Mitu tuberosum  Mitu tuberosum       S  ...    2389.0   \n",
       "3   Mitu tuberosum   Mitu tuberosum  Mitu tuberosum       S  ...    2389.0   \n",
       "4   Mitu tuberosum   Mitu tuberosum  Mitu tuberosum       S  ...    2389.0   \n",
       "\n",
       "   PopDens  Stunting  FoodBiomass Reserve  Forest_cover    NPP  CountryNum  \\\n",
       "0      0.0      14.7    17.695656       1         100.0  207.0          76   \n",
       "1      0.0      14.7    17.695656       1         100.0  207.0          76   \n",
       "2      0.0      14.7    17.695656       1         100.0  207.0          76   \n",
       "3      0.0      14.7    17.695656       1         100.0  207.0          76   \n",
       "4      0.0      14.7    17.695656       1         100.0  207.0          76   \n",
       "\n",
       "  Food Hunted  \n",
       "0  Yes    Yes  \n",
       "1  Yes    Yes  \n",
       "2  Yes    Yes  \n",
       "3  Yes    Yes  \n",
       "4  Yes    Yes  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the datasets\n",
    "bird_data = pd.read_csv(fer_ari_path)\n",
    "mammal_data = read_csv_non_utf(ben_lop_path)\n",
    "\n",
    "bird_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7bd0a8d-f037-4812-9f29-750684d75bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region\n",
       "S America    1414\n",
       "Africa       1164\n",
       "C America     531\n",
       "Asia          172\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mammal_data['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a38ea-558a-460b-a03f-e63e079d1616",
   "metadata": {},
   "source": [
    "# Cross-taxa generalisation\n",
    "\n",
    "Training on birds and evaluating on mammals, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84459e08-779b-472d-9ac9-1103b51c1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on birds and testing on mammals\n"
     ]
    }
   ],
   "source": [
    "# Choosing which dataset to train on - \"mammals\" or \"birds\"\n",
    "train_dataset = 'birds' \n",
    "\n",
    "test_dataset = 'birds' if train_dataset == 'mammals' else 'mammals'\n",
    "print(f'Training on {train_dataset} and testing on {test_dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b0ab5-13fa-4757-9812-bb1e7a77304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligning the two datasets\n",
    "cols = ['Order', 'Family', 'Species', 'ratio', 'X', 'Y', 'Country', 'BM', 'DistKm', 'PopDens', \n",
    "        'Stunting', 'TravTime', 'LivestockBio', 'Reserve']\n",
    "mammal_data = mammal_data[cols]\n",
    "\n",
    "cols = ['Order', 'Family', 'Species', 'RR', 'Latitude', 'Longitude', 'Country', 'Body_Mass', \n",
    "        'Dist_Hunters', 'PopDens', 'Stunting', 'TravDist', 'FoodBiomass', 'Reserve']\n",
    "bird_data = bird_data[cols]\n",
    "bird_data['Reserve'] = bird_data['Reserve'].replace({0 : 'No', 1 : 'Yes'}) # aligning the coding of this binary columns to the mammal dataset\n",
    "\n",
    "bird_data = bird_data.rename(columns = {'RR' : 'ratio', 'Longitude' : 'X', 'Latitude' : 'Y',\n",
    "                                        'Dist_Hunters' : 'DistKm', 'TravDist' : 'TravTime',\n",
    "                                        'FoodBiomass' : 'LivestockBio', 'Body_Mass' : 'BM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11811bd3-2dfa-4441-a5da-c6dbfcffaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "dataset = 'both'\n",
    "data = pd.concat((mammal_data, bird_data), join = 'inner', axis = 0, ignore_index = True)\n",
    "\n",
    "mammal_idxs = [i for i in range(len(mammal_data))]\n",
    "bird_idxs = [i for i in range(len(mammal_data), len(data))]\n",
    "idxs = {'train' : mammal_idxs if train_dataset == 'mammals' else bird_idxs, \n",
    "        'test' : bird_idxs if train_dataset == 'mammals' else mammal_idxs}\n",
    "\n",
    "pp_data = preprocess_data(data, include_indicators = False, standardize = True, log_trans_cont = False,\n",
    "                          polynomial_features = 0, train_test_idxs = idxs, embeddings_to_use = None,\n",
    "                          embeddings_args = None, dataset = dataset)\n",
    "\n",
    "train_data, test_data = pp_data.iloc[idxs['train']].reset_index(drop = True), pp_data.iloc[idxs['test']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74ff63c7-4230-4a21-8e9b-a82b02cd206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "time_budget_mins = 0.1\n",
    "base_path = os.path.join('..', 'model_saves')\n",
    "verbose = 3\n",
    "\n",
    "#  using only shared columns for predictors\n",
    "zero_columns = ['BM', 'DistKm', 'PopDens', 'Stunting', 'TravTime', 'LivestockBio', 'Reserve']\n",
    "nonzero_columns = zero_columns\n",
    "indicator_columns = []\n",
    "\n",
    "zero_metric = balanced_accuracy_FLAML\n",
    "nonzero_metric = 'mse'\n",
    "\n",
    "# Setting up the zero and nonzero models\n",
    "zero_model = AutoML()\n",
    "nonzero_model = AutoML()\n",
    "\n",
    "#  specify fitting paramaters\n",
    "zero_settings = {\n",
    "    'time_budget' : time_budget_mins * 60,  # in seconds\n",
    "    'metric' : zero_metric,\n",
    "    'task' : 'classification',\n",
    "    'log_file_name' : os.path.join(base_path, f'nonlinear_hurdle_ZERO.log'),\n",
    "    'seed' : 1693,\n",
    "    'estimator_list' : ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', \n",
    "                        'extra_tree', 'kneighbor', 'lrl1', 'lrl2'],\n",
    "    'early_stop' : True,\n",
    "    'verbose' : verbose,\n",
    "    'keep_search_state' : True,\n",
    "    'eval_method' : 'cv'\n",
    "}\n",
    "\n",
    "nonzero_settings = {\n",
    "    'time_budget' : time_budget_mins * 60,  # in seconds\n",
    "    'metric' : nonzero_metric,\n",
    "    'task' : 'regression',\n",
    "    'log_file_name' : os.path.join(base_path, f'nonlinear_hurdle_NONZERO.log'),\n",
    "    'seed' : 1693,\n",
    "    'estimator_list' : ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'kneighbor'],\n",
    "    'early_stop' : True,\n",
    "    'verbose' : verbose,\n",
    "    'keep_search_state' : True,\n",
    "    'eval_method' : 'cv'\n",
    "}\n",
    "\n",
    "extirp_pos = False\n",
    "settings = {'zero' : zero_settings, 'nonzero' : nonzero_settings}\n",
    "\n",
    "#  dumping everything into the hurdle model wrapper\n",
    "data_args = {'indicator_columns' : indicator_columns,\n",
    "             'nonzero_columns' : nonzero_columns,\n",
    "             'zero_columns' : zero_columns,\n",
    "             'embeddings_to_use' : None,\n",
    "             'dataset' : dataset}\n",
    "hurdle_model = HurdleModelEstimator(zero_model, nonzero_model, extirp_pos = extirp_pos, \n",
    "                                    data_args = data_args, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8a9910b-fc3c-4861-845b-889e215dd5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the nonzero model...\n",
      "[flaml.automl.logger: 06-25 12:32:02] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 06-25 12:32:02] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 06-25 12:32:02] {1789} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 06-25 12:32:02] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'kneighbor']\n",
      "[flaml.automl.logger: 06-25 12:32:02] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2345} INFO - Estimated sufficient time budget=1259s. Estimated necessary time budget=13s.\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.2s,\testimator lgbm's best error=0.9040,\tbest estimator lgbm's best error=0.9040\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.3s,\testimator lgbm's best error=0.8814,\tbest estimator lgbm's best error=0.8814\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.8814,\tbest estimator lgbm's best error=0.8814\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.6s,\testimator lgbm's best error=0.8814,\tbest estimator lgbm's best error=0.8814\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.7s,\testimator xgboost's best error=0.9046,\tbest estimator lgbm's best error=0.8814\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.7s,\testimator xgboost's best error=0.8834,\tbest estimator lgbm's best error=0.8814\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.8781,\tbest estimator lgbm's best error=0.8781\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.8781,\tbest estimator lgbm's best error=0.8781\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.8757,\tbest estimator lgbm's best error=0.8757\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.8667,\tbest estimator lgbm's best error=0.8667\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 1.1s,\testimator lgbm's best error=0.8667,\tbest estimator lgbm's best error=0.8667\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2392} INFO -  at 1.1s,\testimator lgbm's best error=0.8628,\tbest estimator lgbm's best error=0.8628\n",
      "[flaml.automl.logger: 06-25 12:32:03] {2219} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.8619,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.8619,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 1.3s,\testimator lgbm's best error=0.8619,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 1.4s,\testimator xgboost's best error=0.8834,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 1.4s,\testimator lgbm's best error=0.8619,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 1.5s,\testimator xgboost's best error=0.8742,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.8619,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 1.9s,\testimator extra_tree's best error=0.9207,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 2.0s,\testimator xgboost's best error=0.8742,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2392} INFO -  at 2.1s,\testimator lgbm's best error=0.8619,\tbest estimator lgbm's best error=0.8619\n",
      "[flaml.automl.logger: 06-25 12:32:04] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2392} INFO -  at 2.2s,\testimator lgbm's best error=0.8532,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2219} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2392} INFO -  at 2.4s,\testimator extra_tree's best error=0.9071,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2219} INFO - iteration 24, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2392} INFO -  at 2.6s,\testimator rf's best error=0.8861,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2219} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2392} INFO -  at 2.9s,\testimator extra_tree's best error=0.9012,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2219} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2392} INFO -  at 3.0s,\testimator xgboost's best error=0.8742,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:05] {2219} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2392} INFO -  at 3.2s,\testimator rf's best error=0.8861,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2219} INFO - iteration 28, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2392} INFO -  at 3.6s,\testimator rf's best error=0.8861,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2392} INFO -  at 3.7s,\testimator xgboost's best error=0.8695,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2392} INFO -  at 3.8s,\testimator lgbm's best error=0.8532,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2392} INFO -  at 3.9s,\testimator lgbm's best error=0.8532,\tbest estimator lgbm's best error=0.8532\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2392} INFO -  at 4.0s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2392} INFO -  at 4.1s,\testimator xgboost's best error=0.8661,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:06] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 4.2s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 4.3s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 4.5s,\testimator extra_tree's best error=0.9012,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 4.6s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 4.7s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 4.7s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 4.8s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 4.9s,\testimator xgboost's best error=0.8661,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2392} INFO -  at 5.0s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:07] {2219} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 5.1s,\testimator xgboost's best error=0.8661,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2219} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 5.4s,\testimator extra_tree's best error=0.8970,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2219} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 5.4s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2219} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 5.5s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2219} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 5.6s,\testimator xgboost's best error=0.8574,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2219} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 5.7s,\testimator lgbm's best error=0.8500,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2219} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 5.8s,\testimator xgboost's best error=0.8574,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2219} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 6.0s,\testimator xgboost's best error=0.8574,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2219} INFO - iteration 51, current learner kneighbor\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2392} INFO -  at 6.0s,\testimator kneighbor's best error=1.1336,\tbest estimator lgbm's best error=0.8500\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2628} INFO - retrain lgbm for 0.0s\n",
      "[flaml.automl.logger: 06-25 12:32:08] {2631} INFO - retrained model: LGBMRegressor(colsample_bytree=0.8601195291458197,\n",
      "              learning_rate=0.7065579531057187, max_bin=1023,\n",
      "              min_child_samples=6, n_estimators=1, n_jobs=-1, num_leaves=4,\n",
      "              reg_alpha=0.006101500170587287, reg_lambda=0.03373546766095884,\n",
      "              verbose=-1)\n",
      "[flaml.automl.logger: 06-25 12:32:08] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-25 12:32:08] {1932} INFO - Time taken to find the best model: 3.99226713180542\n",
      "Fitting the zero model...\n",
      "[flaml.automl.logger: 06-25 12:32:09] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 06-25 12:32:09] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 06-25 12:32:09] {1789} INFO - Minimizing error metric: customized metric\n",
      "[flaml.automl.logger: 06-25 12:32:09] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'kneighbor', 'lrl1', 'lrl2']\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2345} INFO - Estimated sufficient time budget=1992s. Estimated necessary time budget=57s.\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.5000,\tbest estimator lgbm's best error=0.5000\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.4843,\tbest estimator lgbm's best error=0.4843\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2392} INFO -  at 0.6s,\testimator lgbm's best error=0.4843,\tbest estimator lgbm's best error=0.4843\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2392} INFO -  at 0.7s,\testimator lgbm's best error=0.4840,\tbest estimator lgbm's best error=0.4840\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2392} INFO -  at 0.7s,\testimator lgbm's best error=0.4840,\tbest estimator lgbm's best error=0.4840\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.4840,\tbest estimator lgbm's best error=0.4840\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.4679,\tbest estimator lgbm's best error=0.4679\n",
      "[flaml.automl.logger: 06-25 12:32:09] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.1s,\testimator lgbm's best error=0.3958,\tbest estimator lgbm's best error=0.3958\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.3958,\tbest estimator lgbm's best error=0.3958\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.3s,\testimator lgbm's best error=0.3958,\tbest estimator lgbm's best error=0.3958\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.4s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.5s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.6s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.8s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.9s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 1.9s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2392} INFO -  at 2.0s,\testimator xgboost's best error=0.4962,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:10] {2219} INFO - iteration 18, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:32:11] {2392} INFO -  at 2.3s,\testimator extra_tree's best error=0.5004,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:11] {2219} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:32:11] {2392} INFO -  at 2.6s,\testimator extra_tree's best error=0.5000,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:11] {2219} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:11] {2392} INFO -  at 2.9s,\testimator rf's best error=0.4785,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:11] {2219} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2392} INFO -  at 3.1s,\testimator rf's best error=0.4785,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2392} INFO -  at 3.2s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2219} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2392} INFO -  at 3.4s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2219} INFO - iteration 24, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2392} INFO -  at 3.7s,\testimator rf's best error=0.4785,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2219} INFO - iteration 25, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2392} INFO -  at 4.0s,\testimator rf's best error=0.4785,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2219} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2392} INFO -  at 4.0s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:12] {2219} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2392} INFO -  at 4.3s,\testimator rf's best error=0.4785,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2219} INFO - iteration 28, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2392} INFO -  at 4.5s,\testimator rf's best error=0.4518,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2392} INFO -  at 4.7s,\testimator xgboost's best error=0.4962,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2392} INFO -  at 4.9s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2392} INFO -  at 5.0s,\testimator lgbm's best error=0.3727,\tbest estimator lgbm's best error=0.3727\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2392} INFO -  at 5.1s,\testimator lgbm's best error=0.3654,\tbest estimator lgbm's best error=0.3654\n",
      "[flaml.automl.logger: 06-25 12:32:13] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2392} INFO -  at 5.2s,\testimator xgboost's best error=0.4962,\tbest estimator lgbm's best error=0.3654\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2392} INFO -  at 5.2s,\testimator lgbm's best error=0.3654,\tbest estimator lgbm's best error=0.3654\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2219} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2392} INFO -  at 5.4s,\testimator lgbm's best error=0.3590,\tbest estimator lgbm's best error=0.3590\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2219} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2392} INFO -  at 5.7s,\testimator lgbm's best error=0.3590,\tbest estimator lgbm's best error=0.3590\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2219} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2392} INFO -  at 5.8s,\testimator lgbm's best error=0.3590,\tbest estimator lgbm's best error=0.3590\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2219} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2392} INFO -  at 5.9s,\testimator lgbm's best error=0.3590,\tbest estimator lgbm's best error=0.3590\n",
      "[flaml.automl.logger: 06-25 12:32:14] {2219} INFO - iteration 39, current learner lrl2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'TimeoutError'> [Errno 14] <frame at 0x1263ce670, file '/Users/emiliolr/miniforge3/envs/life-hunting/lib/python3.12/site-packages/joblib/parallel.py', line 1707, code _retrieve>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-25 12:32:15] {2392} INFO -  at 7.0s,\testimator lrl2's best error=0.5000,\tbest estimator lgbm's best error=0.3590\n",
      "[flaml.automl.logger: 06-25 12:32:15] {2628} INFO - retrain lgbm for 0.1s\n",
      "[flaml.automl.logger: 06-25 12:32:15] {2631} INFO - retrained model: LGBMClassifier(colsample_bytree=0.7568488517531023, learning_rate=1.0,\n",
      "               max_bin=127, min_child_samples=25, n_estimators=1, n_jobs=-1,\n",
      "               num_leaves=11, reg_alpha=0.6359407655146174,\n",
      "               reg_lambda=2.397491917044793, verbose=-1)\n",
      "[flaml.automl.logger: 06-25 12:32:16] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-25 12:32:16] {1932} INFO - Time taken to find the best model: 5.821398019790649\n"
     ]
    }
   ],
   "source": [
    "# Fitting the two constituent models\n",
    "hurdle_model.fit(train_data, fit_args = settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55aa679a-4408-49b7-82dd-7cbdfa85ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold was found to be 0.8\n"
     ]
    }
   ],
   "source": [
    "# Tuning the probability threshold for the zero model\n",
    "X_zero, y_zero, _, _ = get_zero_nonzero_datasets(train_data, extirp_pos = hurdle_model.extirp_pos,\n",
    "                                                 pred = False, **hurdle_model.data_args)\n",
    "y_pred = hurdle_model.zero_model.predict_proba(X_zero)[ : , 1]\n",
    "\n",
    "opt_thresh, _ = test_thresholds(y_pred, y_zero)\n",
    "hurdle_model.prob_thresh = round(opt_thresh, 3)\n",
    "print(f'Optimal threshold was found to be {hurdle_model.prob_thresh}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c7c6501-3df4-479e-9b04-396efa1ab8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test set\n",
    "y_pred = hurdle_model.predict(test_data)\n",
    "y_pred[y_pred != 0] = np.exp(y_pred[y_pred != 0])\n",
    "y_test = test_data['ratio'].copy(deep = True)\n",
    "\n",
    "#  getting DI categories\n",
    "true_DI_cats = ratios_to_DI_cats(y_test)\n",
    "pred_DI_cats = ratios_to_DI_cats(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9c56e5a-711e-4f01-8d37-3fb216af57a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.063\n",
      "MAE (0-1 range): 0.601\n",
      "RMSE: 3.833\n",
      "BA: 0.343\n"
     ]
    }
   ],
   "source": [
    "# Getting performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {round(mae, 3)}')\n",
    "\n",
    "mae_01, _ = mean_absolute_error_range(y_test, y_pred, 0, 1)\n",
    "print(f'MAE (0-1 range): {round(mae_01, 3)}')\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'RMSE: {round(rmse, 3)}')\n",
    "\n",
    "ba = balanced_accuracy_score(true_DI_cats, pred_DI_cats)\n",
    "print(f'BA: {round(ba, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74170a6f-c52f-49d9-8ebd-12e65fe9cd34",
   "metadata": {},
   "source": [
    "# Cross-continent generalisation\n",
    "For mammals, this is test on South America or Africa (and train on everything else), and for birds, this is test on the Neotropical or Indomalayan region (and train on everything else)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0d3aa86-f468-42da-8fa6-2f94aa27cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mammals dataset, testing on S America\n"
     ]
    }
   ],
   "source": [
    "# Choosing which region to train on - \"mammals\" or \"birds\"\n",
    "dataset = 'mammals'\n",
    "test_region = 'S America' # for mammals, either \"S America\" or \"Africa\", and for birds, either \"Neotropic\" or \"Indomalayan\" \n",
    "\n",
    "if dataset == 'mammals':\n",
    "    assert test_region in ['S America', 'Africa'], 'The only valid test regions for mammals are \"S America\" or \"Africa\".' \n",
    "elif dataset == 'birds':\n",
    "    assert test_region in ['Neotropic', 'Indomalayan'], 'The only valid test regions for birds are \"Neotropic\" or \"Indomalayan\".' \n",
    "\n",
    "print(f'{dataset.title()} dataset, testing on {test_region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90a73cf6-5633-46db-87fc-5c287028aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "data = mammal_data if dataset == 'mammals' else bird_data\n",
    "col = 'Region' if dataset == 'mammals' else 'Realm'\n",
    "\n",
    "test_idxs = data.index[data[col] == test_region].to_list()\n",
    "train_idxs = [i for i in data.index if i not in test_idxs]\n",
    "idxs = {'train' : train_idxs, 'test' : test_idxs}\n",
    "\n",
    "pp_data = preprocess_data(data, include_indicators = False, standardize = True, log_trans_cont = False,\n",
    "                          polynomial_features = 0, train_test_idxs = idxs, embeddings_to_use = None,\n",
    "                          embeddings_args = None, dataset = dataset)\n",
    "\n",
    "train_data, test_data = pp_data.iloc[idxs['train']], pp_data.iloc[idxs['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e2b44de-2cd3-43c4-99d0-4f02e4dc05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "time_budget_mins = 0.1\n",
    "base_path = os.path.join('..', 'model_saves')\n",
    "verbose = 3\n",
    "\n",
    "# Getting the predictors\n",
    "if dataset == 'mammals':\n",
    "    zero_columns = ['BM', 'DistKm', 'PopDens', 'Stunting', 'TravTime', 'LivestockBio', 'Reserve', 'Literacy']\n",
    "elif dataset == 'birds':\n",
    "    zero_columns = ['Dist_Hunters', 'TravDist', 'PopDens', 'Stunting', 'FoodBiomass', 'Forest_cover', 'NPP', 'Body_Mass']\n",
    "nonzero_columns = zero_columns\n",
    "indicator_columns = []\n",
    "\n",
    "zero_metric = balanced_accuracy_FLAML\n",
    "nonzero_metric = 'mse'\n",
    "\n",
    "# Setting up the zero and nonzero models\n",
    "zero_model = AutoML()\n",
    "nonzero_model = AutoML()\n",
    "\n",
    "#  specify fitting paramaters\n",
    "zero_settings = {\n",
    "    'time_budget' : time_budget_mins * 60,  # in seconds\n",
    "    'metric' : zero_metric,\n",
    "    'task' : 'classification',\n",
    "    'log_file_name' : os.path.join(base_path, f'nonlinear_hurdle_ZERO.log'),\n",
    "    'seed' : 1693,\n",
    "    'estimator_list' : ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', \n",
    "                        'extra_tree', 'kneighbor', 'lrl1', 'lrl2'],\n",
    "    'early_stop' : True,\n",
    "    'verbose' : verbose,\n",
    "    'keep_search_state' : True,\n",
    "    'eval_method' : 'cv'\n",
    "}\n",
    "\n",
    "nonzero_settings = {\n",
    "    'time_budget' : time_budget_mins * 60,  # in seconds\n",
    "    'metric' : nonzero_metric,\n",
    "    'task' : 'regression',\n",
    "    'log_file_name' : os.path.join(base_path, f'nonlinear_hurdle_NONZERO.log'),\n",
    "    'seed' : 1693,\n",
    "    'estimator_list' : ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'kneighbor'],\n",
    "    'early_stop' : True,\n",
    "    'verbose' : verbose,\n",
    "    'keep_search_state' : True,\n",
    "    'eval_method' : 'cv'\n",
    "}\n",
    "\n",
    "extirp_pos = False\n",
    "settings = {'zero' : zero_settings, 'nonzero' : nonzero_settings}\n",
    "\n",
    "#  dumping everything into the hurdle model wrapper\n",
    "data_args = {'indicator_columns' : indicator_columns,\n",
    "             'nonzero_columns' : nonzero_columns,\n",
    "             'zero_columns' : zero_columns,\n",
    "             'embeddings_to_use' : None,\n",
    "             'dataset' : dataset}\n",
    "hurdle_model = HurdleModelEstimator(zero_model, nonzero_model, extirp_pos = extirp_pos, \n",
    "                                    data_args = data_args, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6babba6b-2ceb-449b-8172-7c09c1dfb065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the nonzero model...\n",
      "[flaml.automl.logger: 06-25 12:59:00] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 06-25 12:59:00] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 06-25 12:59:00] {1789} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 06-25 12:59:00] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'kneighbor']\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2345} INFO - Estimated sufficient time budget=2429s. Estimated necessary time budget=24s.\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2392} INFO -  at 0.3s,\testimator lgbm's best error=0.9901,\tbest estimator lgbm's best error=0.9901\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.9397,\tbest estimator lgbm's best error=0.9397\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.9397,\tbest estimator lgbm's best error=0.9397\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2392} INFO -  at 0.7s,\testimator lgbm's best error=0.9229,\tbest estimator lgbm's best error=0.9229\n",
      "[flaml.automl.logger: 06-25 12:59:00] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.9229,\tbest estimator lgbm's best error=0.9229\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.9229,\tbest estimator lgbm's best error=0.9229\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.9127,\tbest estimator lgbm's best error=0.9127\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.8843,\tbest estimator lgbm's best error=0.8843\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.1s,\testimator lgbm's best error=0.8843,\tbest estimator lgbm's best error=0.8843\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.8719,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.3s,\testimator lgbm's best error=0.8719,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.3s,\testimator lgbm's best error=0.8719,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.4s,\testimator lgbm's best error=0.8719,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.5s,\testimator lgbm's best error=0.8719,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.6s,\testimator lgbm's best error=0.8719,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.8719,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:01] {2219} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2392} INFO -  at 1.8s,\testimator xgboost's best error=0.9904,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2219} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2392} INFO -  at 1.9s,\testimator xgboost's best error=0.9313,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2219} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2392} INFO -  at 2.0s,\testimator xgboost's best error=0.9313,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2219} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2392} INFO -  at 2.1s,\testimator xgboost's best error=0.9306,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2219} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2392} INFO -  at 2.3s,\testimator extra_tree's best error=0.9901,\tbest estimator lgbm's best error=0.8719\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2219} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2392} INFO -  at 2.4s,\testimator lgbm's best error=0.8644,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2392} INFO -  at 2.5s,\testimator lgbm's best error=0.8644,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2219} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2392} INFO -  at 2.7s,\testimator extra_tree's best error=0.9782,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:02] {2219} INFO - iteration 24, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:59:03] {2392} INFO -  at 3.0s,\testimator rf's best error=0.9623,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:03] {2219} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:03] {2392} INFO -  at 3.3s,\testimator extra_tree's best error=0.9528,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:03] {2219} INFO - iteration 26, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:59:03] {2392} INFO -  at 3.6s,\testimator rf's best error=0.9450,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:03] {2219} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2392} INFO -  at 3.9s,\testimator rf's best error=0.9191,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2219} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2392} INFO -  at 4.2s,\testimator extra_tree's best error=0.9528,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2219} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2392} INFO -  at 4.5s,\testimator rf's best error=0.9191,\tbest estimator lgbm's best error=0.8644\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2392} INFO -  at 4.6s,\testimator lgbm's best error=0.8549,\tbest estimator lgbm's best error=0.8549\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2392} INFO -  at 4.7s,\testimator lgbm's best error=0.8549,\tbest estimator lgbm's best error=0.8549\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2392} INFO -  at 4.8s,\testimator lgbm's best error=0.8549,\tbest estimator lgbm's best error=0.8549\n",
      "[flaml.automl.logger: 06-25 12:59:04] {2219} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2392} INFO -  at 4.9s,\testimator lgbm's best error=0.8357,\tbest estimator lgbm's best error=0.8357\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2392} INFO -  at 5.0s,\testimator lgbm's best error=0.8357,\tbest estimator lgbm's best error=0.8357\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2219} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2392} INFO -  at 5.2s,\testimator lgbm's best error=0.8357,\tbest estimator lgbm's best error=0.8357\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2219} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2392} INFO -  at 5.5s,\testimator extra_tree's best error=0.9417,\tbest estimator lgbm's best error=0.8357\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2219} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2392} INFO -  at 5.7s,\testimator lgbm's best error=0.8357,\tbest estimator lgbm's best error=0.8357\n",
      "[flaml.automl.logger: 06-25 12:59:05] {2219} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2392} INFO -  at 5.9s,\testimator lgbm's best error=0.8357,\tbest estimator lgbm's best error=0.8357\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2219} INFO - iteration 39, current learner kneighbor\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2392} INFO -  at 6.0s,\testimator kneighbor's best error=1.0314,\tbest estimator lgbm's best error=0.8357\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2628} INFO - retrain lgbm for 0.0s\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2631} INFO - retrained model: LGBMRegressor(colsample_bytree=0.7081104588133883,\n",
      "              learning_rate=0.49505289892502663, max_bin=63,\n",
      "              min_child_samples=53, n_estimators=1, n_jobs=-1, num_leaves=36,\n",
      "              reg_alpha=0.004624144436559042, reg_lambda=0.5546930573825773,\n",
      "              verbose=-1)\n",
      "[flaml.automl.logger: 06-25 12:59:06] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-25 12:59:06] {1932} INFO - Time taken to find the best model: 4.943871021270752\n",
      "Fitting the zero model...\n",
      "[flaml.automl.logger: 06-25 12:59:06] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 06-25 12:59:06] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 06-25 12:59:06] {1789} INFO - Minimizing error metric: customized metric\n",
      "[flaml.automl.logger: 06-25 12:59:06] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'kneighbor', 'lrl1', 'lrl2']\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2345} INFO - Estimated sufficient time budget=2394s. Estimated necessary time budget=68s.\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.5000,\tbest estimator lgbm's best error=0.5000\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.4820,\tbest estimator lgbm's best error=0.4820\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2392} INFO -  at 0.6s,\testimator lgbm's best error=0.4820,\tbest estimator lgbm's best error=0.4820\n",
      "[flaml.automl.logger: 06-25 12:59:06] {2219} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.4492,\tbest estimator lgbm's best error=0.4492\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.4492,\tbest estimator lgbm's best error=0.4492\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.4492,\tbest estimator lgbm's best error=0.4492\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.4013,\tbest estimator lgbm's best error=0.4013\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 1.3s,\testimator lgbm's best error=0.3701,\tbest estimator lgbm's best error=0.3701\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 1.4s,\testimator lgbm's best error=0.3701,\tbest estimator lgbm's best error=0.3701\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 1.5s,\testimator lgbm's best error=0.3701,\tbest estimator lgbm's best error=0.3701\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 1.6s,\testimator lgbm's best error=0.3701,\tbest estimator lgbm's best error=0.3701\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.3449,\tbest estimator lgbm's best error=0.3449\n",
      "[flaml.automl.logger: 06-25 12:59:07] {2219} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 1.8s,\testimator lgbm's best error=0.3449,\tbest estimator lgbm's best error=0.3449\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 1.8s,\testimator lgbm's best error=0.3449,\tbest estimator lgbm's best error=0.3449\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 1.9s,\testimator lgbm's best error=0.3449,\tbest estimator lgbm's best error=0.3449\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.0s,\testimator lgbm's best error=0.3449,\tbest estimator lgbm's best error=0.3449\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.1s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.2s,\testimator xgboost's best error=0.5000,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.3s,\testimator xgboost's best error=0.4787,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.3s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.4s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.5s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.6s,\testimator xgboost's best error=0.4787,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2392} INFO -  at 2.7s,\testimator xgboost's best error=0.4787,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:08] {2219} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:09] {2392} INFO -  at 2.7s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:09] {2219} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:09] {2392} INFO -  at 3.0s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:09] {2219} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:09] {2392} INFO -  at 3.3s,\testimator extra_tree's best error=0.5000,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:09] {2219} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:09] {2392} INFO -  at 3.6s,\testimator extra_tree's best error=0.5000,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:09] {2219} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2392} INFO -  at 3.9s,\testimator extra_tree's best error=0.5000,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2219} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2392} INFO -  at 4.3s,\testimator rf's best error=0.4980,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2392} INFO -  at 4.4s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2392} INFO -  at 4.6s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2392} INFO -  at 4.7s,\testimator lgbm's best error=0.3312,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:10] {2219} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:11] {2392} INFO -  at 4.9s,\testimator extra_tree's best error=0.5000,\tbest estimator lgbm's best error=0.3312\n",
      "[flaml.automl.logger: 06-25 12:59:11] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 06-25 12:59:11] {2392} INFO -  at 5.1s,\testimator lgbm's best error=0.3148,\tbest estimator lgbm's best error=0.3148\n",
      "[flaml.automl.logger: 06-25 12:59:11] {2219} INFO - iteration 35, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:59:11] {2392} INFO -  at 5.4s,\testimator rf's best error=0.4980,\tbest estimator lgbm's best error=0.3148\n",
      "[flaml.automl.logger: 06-25 12:59:11] {2219} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 06-25 12:59:11] {2392} INFO -  at 5.6s,\testimator extra_tree's best error=0.5000,\tbest estimator lgbm's best error=0.3148\n",
      "[flaml.automl.logger: 06-25 12:59:11] {2219} INFO - iteration 37, current learner rf\n",
      "[flaml.automl.logger: 06-25 12:59:12] {2392} INFO -  at 5.9s,\testimator rf's best error=0.4980,\tbest estimator lgbm's best error=0.3148\n",
      "[flaml.automl.logger: 06-25 12:59:12] {2219} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 06-25 12:59:12] {2392} INFO -  at 5.9s,\testimator xgboost's best error=0.4319,\tbest estimator lgbm's best error=0.3148\n",
      "[flaml.automl.logger: 06-25 12:59:12] {2219} INFO - iteration 39, current learner lrl2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'TimeoutError'> [Errno 14] <frame at 0x166dff780, file '/Users/emiliolr/miniforge3/envs/life-hunting/lib/python3.12/site-packages/joblib/parallel.py', line 1707, code _retrieve>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-25 12:59:13] {2392} INFO -  at 7.0s,\testimator lrl2's best error=0.5000,\tbest estimator lgbm's best error=0.3148\n",
      "[flaml.automl.logger: 06-25 12:59:13] {2628} INFO - retrain lgbm for 0.0s\n",
      "[flaml.automl.logger: 06-25 12:59:13] {2631} INFO - retrained model: LGBMClassifier(colsample_bytree=0.5587141427298338, learning_rate=1.0,\n",
      "               max_bin=1023, min_child_samples=41, n_estimators=1, n_jobs=-1,\n",
      "               num_leaves=19, reg_alpha=0.03170864738238316,\n",
      "               reg_lambda=1.0104135255795006, verbose=-1)\n",
      "[flaml.automl.logger: 06-25 12:59:13] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-25 12:59:13] {1932} INFO - Time taken to find the best model: 5.09814190864563\n"
     ]
    }
   ],
   "source": [
    "# Fitting the two constituent models\n",
    "hurdle_model.fit(train_data, fit_args = settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14bd6dc7-8086-4bbe-af06-8ae150d62a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold was found to be 0.8\n"
     ]
    }
   ],
   "source": [
    "# Tuning the probability threshold for the zero model\n",
    "X_zero, y_zero, _, _ = get_zero_nonzero_datasets(train_data, extirp_pos = hurdle_model.extirp_pos,\n",
    "                                                 pred = False, **hurdle_model.data_args)\n",
    "y_pred = hurdle_model.zero_model.predict_proba(X_zero)[ : , 1]\n",
    "\n",
    "opt_thresh, _ = test_thresholds(y_pred, y_zero)\n",
    "hurdle_model.prob_thresh = round(opt_thresh, 3)\n",
    "print(f'Optimal threshold was found to be {hurdle_model.prob_thresh}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3edba21a-6eb6-41ad-a2c7-4341eb14811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test set\n",
    "y_pred = hurdle_model.predict(test_data)\n",
    "y_pred[y_pred != 0] = np.exp(y_pred[y_pred != 0])\n",
    "y_test = test_data['ratio'].copy(deep = True)\n",
    "\n",
    "#  getting DI categories\n",
    "true_DI_cats = ratios_to_DI_cats(y_test)\n",
    "pred_DI_cats = ratios_to_DI_cats(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28b54a09-17b0-4ced-8eb1-6622f1eb320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.921\n",
      "MAE (0-1 range): 0.407\n",
      "RMSE: 2.564\n",
      "BA: 0.436\n"
     ]
    }
   ],
   "source": [
    "# Getting performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {round(mae, 3)}')\n",
    "\n",
    "mae_01, _ = mean_absolute_error_range(y_test, y_pred, 0, 1)\n",
    "print(f'MAE (0-1 range): {round(mae_01, 3)}')\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'RMSE: {round(rmse, 3)}')\n",
    "\n",
    "ba = balanced_accuracy_score(true_DI_cats, pred_DI_cats)\n",
    "print(f'BA: {round(ba, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e680ec-310c-48cf-a72c-accb412a6b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
