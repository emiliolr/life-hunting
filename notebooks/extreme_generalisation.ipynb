{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ccc35ff-7297-4057-96ef-9dc1333bc4c8",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08676b88-b0cc-4164-b261-269c24cacf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from pymer4 import Lmer\n",
    "from flaml import AutoML\n",
    "\n",
    "from utils import read_csv_non_utf, preprocess_data, get_zero_nonzero_datasets, test_thresholds, ratios_to_DI_cats\n",
    "from model_utils import HurdleModelEstimator, PymerModelWrapper\n",
    "from custom_metrics import balanced_accuracy_FLAML, mean_absolute_error_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd025bc-f9fb-4b3a-b8f9-880619219724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in general configuration\n",
    "with open('../config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Getting filepaths\n",
    "gdrive_fp = config['gdrive_path']\n",
    "LIFE_fp = config['LIFE_folder']\n",
    "dataset_fp = config['datasets_path']\n",
    "benitez_lopez2019 = config['indiv_data_paths']['benitez_lopez2019']\n",
    "ferreiro_arias2024 = config['indiv_data_paths']['ferreiro_arias2024']\n",
    "\n",
    "ben_lop_path = os.path.join(gdrive_fp, LIFE_fp, dataset_fp, benitez_lopez2019)\n",
    "fer_ari_path = os.path.join(gdrive_fp, LIFE_fp, dataset_fp, ferreiro_arias2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e52eb47-8914-4a9a-844f-7fa898e6c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the datasets\n",
    "bird_data = pd.read_csv(fer_ari_path)\n",
    "mammal_data = read_csv_non_utf(ben_lop_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a38ea-558a-460b-a03f-e63e079d1616",
   "metadata": {},
   "source": [
    "# Cross-taxa generalisation\n",
    "\n",
    "Training on birds and evaluating on mammals, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "84459e08-779b-472d-9ac9-1103b51c1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on mammals and testing on birds\n"
     ]
    }
   ],
   "source": [
    "# Choosing which dataset to train on - \"mammals\" or \"birds\"\n",
    "train_dataset = 'mammals' \n",
    "\n",
    "test_dataset = 'birds' if train_dataset == 'mammals' else 'mammals'\n",
    "print(f'Training on {train_dataset} and testing on {test_dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "74ff63c7-4230-4a21-8e9b-a82b02cd206f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_regressor\n"
     ]
    }
   ],
   "source": [
    "# Choosing the model to use - pymer, FLAML_hurdle, or dummy_regressor\n",
    "model_to_use = 'dummy_regressor'\n",
    "\n",
    "if model_to_use == 'pymer':\n",
    "    #  setting up the equations for each model\n",
    "    if train_dataset == 'mammals':\n",
    "        formula_zero = 'local_extirpation ~ BM + DistKm + I(DistKm^2) + PopDens + Stunting + Reserve + (1|Country) + (1|Species)'\n",
    "        formula_nonzero = 'RR ~ BM + DistKm + I(DistKm^2) + PopDens + I(PopDens^2) + BM*DistKm + (1|Country) + (1|Species)'\n",
    "    elif dataset == 'birds':\n",
    "        formula_zero = 'local_extirpation ~ BM + DistKm + TravTime + PopDens + Stunting + Reserve + BM*DistKm + BM*TravTime + BM*Stunting + (1|Country) + (1|Species)'\n",
    "        formula_nonzero = 'RR ~ BM + DistKm + TravTime + PopDens + Stunting + Reserve + BM*DistKm + BM*TravTime + BM*Stunting + (1|Country) + (1|Species)'\n",
    "    \n",
    "    control_str = \"optimizer='bobyqa', optCtrl=list(maxfun=1e5)\"\n",
    "\n",
    "    #  hurdle model params\n",
    "    use_rfx = False\n",
    "    extirp_pos = False\n",
    "\n",
    "    outlier_cutoff = 15 if dataset == 'mammals' else 5\n",
    "    data_args = {'outlier_cutoff' : outlier_cutoff, 'dataset' : dataset}\n",
    "\n",
    "    #  setting up the hurdle model\n",
    "    zero_model = PymerModelWrapper(Lmer, formula = formula_zero, family = 'binomial', control_str = control_str, \n",
    "                                   use_rfx = use_rfx)\n",
    "    nonzero_model = PymerModelWrapper(Lmer, formula = formula_nonzero, family = 'gaussian', control_str = control_str, \n",
    "                                      use_rfx = use_rfx)\n",
    "\n",
    "    hurdle_model = HurdleModelEstimator(zero_model, nonzero_model, extirp_pos = extirp_pos, data_args = data_args,\n",
    "                                        verbose = True)\n",
    "\n",
    "    fit_args = None\n",
    "    pp_args = {'include_indicators' : False,\n",
    "               'include_categorical' : True,\n",
    "               'polynomial_features' : 0,\n",
    "               'log_trans_cont' : True,\n",
    "               'dataset' : 'both'}\n",
    "\n",
    "    #  results saving params\n",
    "    model_name = 'pymer_hurdle'\n",
    "    model_name += '_w_rfx' if use_rfx else '_wo_rfx'\n",
    "\n",
    "elif model_to_use == 'FLAML_hurdle':\n",
    "    #  general parameters\n",
    "    time_budget_mins = 0.1\n",
    "    model_name = f'FLAML_hurdle_{time_budget_mins}mins'\n",
    "    base_path = os.path.join('..', 'model_saves')\n",
    "    verbose = 3\n",
    "    \n",
    "    #  getting the predictors\n",
    "    zero_columns = ['BM', 'DistKm', 'PopDens', 'Stunting', 'TravTime', 'LivestockBio', 'Reserve']\n",
    "    nonzero_columns = zero_columns\n",
    "    indicator_columns = []\n",
    "    \n",
    "    zero_metric = balanced_accuracy_FLAML\n",
    "    nonzero_metric = 'mse'\n",
    "    \n",
    "    #  setting up the zero and nonzero models\n",
    "    zero_model = AutoML()\n",
    "    nonzero_model = AutoML()\n",
    "    \n",
    "    #  specify fitting paramaters\n",
    "    zero_settings = {\n",
    "        'time_budget' : time_budget_mins * 60,  # in seconds\n",
    "        'metric' : zero_metric,\n",
    "        'task' : 'classification',\n",
    "        'log_file_name' : os.path.join(base_path, f'nonlinear_hurdle_ZERO.log'),\n",
    "        'seed' : 1693,\n",
    "        'estimator_list' : ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', \n",
    "                            'extra_tree', 'kneighbor', 'lrl1', 'lrl2'],\n",
    "        'early_stop' : True,\n",
    "        'verbose' : verbose,\n",
    "        'keep_search_state' : True,\n",
    "        'eval_method' : 'cv'\n",
    "    }\n",
    "    \n",
    "    nonzero_settings = {\n",
    "        'time_budget' : time_budget_mins * 60,  # in seconds\n",
    "        'metric' : nonzero_metric,\n",
    "        'task' : 'regression',\n",
    "        'log_file_name' : os.path.join(base_path, f'nonlinear_hurdle_NONZERO.log'),\n",
    "        'seed' : 1693,\n",
    "        'estimator_list' : ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'kneighbor'],\n",
    "        'early_stop' : True,\n",
    "        'verbose' : verbose,\n",
    "        'keep_search_state' : True,\n",
    "        'eval_method' : 'cv'\n",
    "    }\n",
    "    \n",
    "    extirp_pos = False\n",
    "    fit_args = {'zero' : zero_settings, 'nonzero' : nonzero_settings}\n",
    "    \n",
    "    #  dumping everything into the hurdle model wrapper\n",
    "    data_args = {'indicator_columns' : indicator_columns,\n",
    "                 'nonzero_columns' : nonzero_columns,\n",
    "                 'zero_columns' : zero_columns,\n",
    "                 'embeddings_to_use' : None,\n",
    "                 'dataset' : 'both'}\n",
    "    hurdle_model = HurdleModelEstimator(zero_model, nonzero_model, extirp_pos = extirp_pos, \n",
    "                                        data_args = data_args, verbose = True)\n",
    "\n",
    "    #  defining preprocessing\n",
    "    pp_args = {'include_indicators' : False,\n",
    "               'include_categorical' : False,\n",
    "               'polynomial_features' : 0,\n",
    "               'log_trans_cont' : False,\n",
    "               'dataset' : dataset,\n",
    "               'embeddings_to_use' : None}\n",
    "\n",
    "elif model_to_use == 'dummy_regressor':\n",
    "    strat = 'mean' # either mean or median\n",
    "    model = DummyRegressor(strategy = strat)\n",
    "    \n",
    "    pp_args = {'include_indicators' : False,\n",
    "               'include_categorical' : False,\n",
    "               'polynomial_features' : 0,\n",
    "               'log_trans_cont' : False,\n",
    "               'dataset' : 'both'}\n",
    "\n",
    "    #  results saving params\n",
    "    model_name = 'dummy_regressor'\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9f3b0ab5-13fa-4757-9812-bb1e7a77304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligning the two datasets\n",
    "cols = ['Order', 'Family', 'Species', 'ratio', 'X', 'Y', 'Country', 'BM', 'DistKm', 'PopDens', \n",
    "        'Stunting', 'TravTime', 'LivestockBio', 'Reserve']\n",
    "mammal_data_sub = mammal_data[cols].copy(deep = True)\n",
    "\n",
    "cols = ['Order', 'Family', 'Species', 'RR', 'Latitude', 'Longitude', 'Country', 'Body_Mass', \n",
    "        'Dist_Hunters', 'PopDens', 'Stunting', 'TravDist', 'FoodBiomass', 'Reserve']\n",
    "bird_data_sub = bird_data[cols].copy(deep = True)\n",
    "bird_data_sub['Reserve'] = bird_data_sub['Reserve'].replace({0 : 'No', 1 : 'Yes'}) # aligning the coding of this binary columns to the mammal dataset\n",
    "\n",
    "bird_data_sub = bird_data_sub.rename(columns = {'RR' : 'ratio', 'Longitude' : 'X', 'Latitude' : 'Y',\n",
    "                                                'Dist_Hunters' : 'DistKm', 'TravDist' : 'TravTime',\n",
    "                                                'FoodBiomass' : 'LivestockBio', 'Body_Mass' : 'BM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "11811bd3-2dfa-4441-a5da-c6dbfcffaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "dataset = 'both'\n",
    "data = pd.concat((mammal_data_sub, bird_data_sub), join = 'inner', axis = 0, ignore_index = True)\n",
    "\n",
    "mammal_idxs = [i for i in range(len(mammal_data_sub))]\n",
    "bird_idxs = [i for i in range(len(mammal_data_sub), len(data))]\n",
    "idxs = {'train' : mammal_idxs if train_dataset == 'mammals' else bird_idxs, \n",
    "        'test' : bird_idxs if train_dataset == 'mammals' else mammal_idxs}\n",
    "\n",
    "pp_data = preprocess_data(data, standardize = True, train_test_idxs = idxs, **pp_args)\n",
    "\n",
    "train_data, test_data = pp_data.iloc[idxs['train']].reset_index(drop = True), pp_data.iloc[idxs['test']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e8a9910b-fc3c-4861-845b-889e215dd5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "if model_to_use in ['FLAML_hurdle', 'pymer']:\n",
    "    hurdle_model.fit(train_data, fit_args = fit_args)\n",
    "elif model_to_use == 'dummy_regressor':\n",
    "    X_train, y_train = train_data.drop(columns = resp_col), train_data[resp_col]\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "55aa679a-4408-49b7-82dd-7cbdfa85ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the probability threshold for the zero model\n",
    "if model_to_use in ['FLAML_hurdle', 'pymer']:\n",
    "    X_zero, y_zero, _, _ = get_zero_nonzero_datasets(train_data, extirp_pos = hurdle_model.extirp_pos,\n",
    "                                                     pred = False, **hurdle_model.data_args)\n",
    "    y_pred = hurdle_model.zero_model.predict_proba(X_zero)[ : , 1]\n",
    "    \n",
    "    opt_thresh, _ = test_thresholds(y_pred, y_zero)\n",
    "    hurdle_model.prob_thresh = round(opt_thresh, 3)\n",
    "    print(f'Optimal threshold was found to be {hurdle_model.prob_thresh}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7c7c6501-3df4-479e-9b04-396efa1ab8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: dummy_regressor_SPECIAL_mammals-->birds.csv\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the test set\n",
    "if model_to_use in ['FLAML_hurdle', 'pymer']:\n",
    "    y_pred = hurdle_model.predict(test_data)\n",
    "elif model_to_use == 'dummy_regressor':\n",
    "    X_test = test_data.drop(columns = resp_col)\n",
    "    y_pred = model.predict(X_test)\n",
    "if model_to_use in ['FLAML_hurdle', 'pymer']:\n",
    "    y_pred[y_pred != 0] = np.exp(y_pred[y_pred != 0])\n",
    "\n",
    "y_test = test_data[resp_col].copy(deep = True)\n",
    "\n",
    "#  getting DI categories\n",
    "true_DI_cats = ratios_to_DI_cats(y_test)\n",
    "pred_DI_cats = ratios_to_DI_cats(y_pred)\n",
    "\n",
    "#  saving predictions\n",
    "save_filename = f'{model_name}_SPECIAL_{train_dataset}-->{test_dataset}.csv'\n",
    "preds_df = pd.DataFrame({'index' : test_data.index, \n",
    "                         'actual' : y_test,\n",
    "                         'predicted' : y_pred})\n",
    "preds_df = preds_df.set_index('index').sort_index()\n",
    "\n",
    "preds_df.to_csv(os.path.join('..', 'results', 'raw_predictions', save_filename))\n",
    "print(f'Results saved to: {save_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d9c56e5a-711e-4f01-8d37-3fb216af57a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.961\n",
      "MAE (0-1 range): 0.774\n",
      "RMSE: 1.726\n",
      "BA: 0.333\n"
     ]
    }
   ],
   "source": [
    "# Getting performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {round(mae, 3)}')\n",
    "\n",
    "mae_01, _ = mean_absolute_error_range(y_test, y_pred, 0, 1)\n",
    "print(f'MAE (0-1 range): {round(mae_01, 3)}')\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'RMSE: {round(rmse, 3)}')\n",
    "\n",
    "ba = balanced_accuracy_score(true_DI_cats, pred_DI_cats)\n",
    "print(f'BA: {round(ba, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74170a6f-c52f-49d9-8ebd-12e65fe9cd34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Cross-continent generalisation\n",
    "For mammals, this is test on South America or Africa (and train on everything else), and for birds, this is test on the Neotropical or Indomalayan region (and train on everything else)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0d3aa86-f468-42da-8fa6-2f94aa27cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mammals dataset, testing on Africa\n"
     ]
    }
   ],
   "source": [
    "# Choosing which region to train on - \"mammals\" or \"birds\"\n",
    "dataset = 'mammals'\n",
    "test_region = 'Africa' # for mammals, either \"S America\" or \"Africa\", and for birds, either \"Neotropic\" or \"Indomalayan\" \n",
    "\n",
    "if dataset == 'mammals':\n",
    "    assert test_region in ['S America', 'Africa'], 'The only valid test regions for mammals are \"S America\" or \"Africa\".' \n",
    "elif dataset == 'birds':\n",
    "    assert test_region in ['Neotropic', 'Indomalayan'], 'The only valid test regions for birds are \"Neotropic\" or \"Indomalayan\".' \n",
    "\n",
    "print(f'{dataset.title()} dataset, testing on {test_region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e2b44de-2cd3-43c4-99d0-4f02e4dc05f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_regressor\n"
     ]
    }
   ],
   "source": [
    "# Choosing the model to use - pymer, FLAML_hurdle, or dummy_regressor\n",
    "model_to_use = 'dummy_regressor'\n",
    "\n",
    "if model_to_use == 'pymer':\n",
    "    #  setting up the equations for each model\n",
    "    if dataset == 'mammals':\n",
    "        formula_zero = 'local_extirpation ~ BM + DistKm + I(DistKm^2) + PopDens + Stunting + Reserve + (1|Country) + (1|Species) + (1|Study)'\n",
    "        formula_nonzero = 'RR ~ BM + DistKm + I(DistKm^2) + PopDens + I(PopDens^2) + BM*DistKm + (1|Country) + (1|Species) + (1|Study)'\n",
    "    elif dataset == 'birds':\n",
    "        formula_zero = 'local_extirpation ~ Body_Mass + Dist_Hunters + TravDist + PopDens + Stunting + NPP + Reserve + Body_Mass*Dist_Hunters + Body_Mass*TravDist + Body_Mass*Stunting + NPP*Dist_Hunters + (1|Country) + (1|Species)'\n",
    "        formula_nonzero = 'RR ~ Body_Mass + Dist_Hunters + TravDist + PopDens + Stunting + NPP + Reserve + Body_Mass*Dist_Hunters + Body_Mass*TravDist + Body_Mass*Stunting + NPP*Dist_Hunters + (1|Country) + (1|Species)'\n",
    "    \n",
    "    control_str = \"optimizer='bobyqa', optCtrl=list(maxfun=1e5)\"\n",
    "\n",
    "    #  hurdle model params\n",
    "    use_rfx = False\n",
    "    extirp_pos = False\n",
    "\n",
    "    outlier_cutoff = 15 if dataset == 'mammals' else 5\n",
    "    data_args = {'outlier_cutoff' : outlier_cutoff, 'dataset' : dataset}\n",
    "\n",
    "    #  setting up the hurdle model\n",
    "    zero_model = PymerModelWrapper(Lmer, formula = formula_zero, family = 'binomial', control_str = control_str, \n",
    "                                   use_rfx = use_rfx)\n",
    "    nonzero_model = PymerModelWrapper(Lmer, formula = formula_nonzero, family = 'gaussian', control_str = control_str, \n",
    "                                      use_rfx = use_rfx)\n",
    "\n",
    "    hurdle_model = HurdleModelEstimator(zero_model, nonzero_model, extirp_pos = extirp_pos, data_args = data_args,\n",
    "                                        verbose = True)\n",
    "\n",
    "    fit_args = None\n",
    "    pp_args = {'include_indicators' : False,\n",
    "               'include_categorical' : True,\n",
    "               'polynomial_features' : 0,\n",
    "               'log_trans_cont' : True,\n",
    "               'dataset' : dataset}\n",
    "\n",
    "    #  results saving params\n",
    "    model_name = 'pymer_hurdle'\n",
    "    model_name += '_w_rfx' if use_rfx else '_wo_rfx'\n",
    "\n",
    "elif model_to_use == 'FLAML_hurdle':\n",
    "    #  general parameters\n",
    "    time_budget_mins = 0.1\n",
    "    model_name = f'FLAML_hurdle_{time_budget_mins}mins'\n",
    "    base_path = os.path.join('..', 'model_saves')\n",
    "    verbose = 3\n",
    "    \n",
    "    #  getting the predictors\n",
    "    if dataset == 'mammals':\n",
    "        zero_columns = ['BM', 'DistKm', 'PopDens', 'Stunting', 'TravTime', 'LivestockBio', 'Reserve', 'Literacy']\n",
    "    elif dataset == 'birds':\n",
    "        zero_columns = ['Dist_Hunters', 'TravDist', 'PopDens', 'Stunting', 'FoodBiomass', 'Forest_cover', 'NPP', 'Body_Mass']\n",
    "    nonzero_columns = zero_columns\n",
    "    indicator_columns = []\n",
    "    \n",
    "    zero_metric = balanced_accuracy_FLAML\n",
    "    nonzero_metric = 'mse'\n",
    "    \n",
    "    #  setting up the zero and nonzero models\n",
    "    zero_model = AutoML()\n",
    "    nonzero_model = AutoML()\n",
    "    \n",
    "    #  specify fitting paramaters\n",
    "    zero_settings = {\n",
    "        'time_budget' : time_budget_mins * 60,  # in seconds\n",
    "        'metric' : zero_metric,\n",
    "        'task' : 'classification',\n",
    "        'log_file_name' : os.path.join(base_path, f'nonlinear_hurdle_ZERO.log'),\n",
    "        'seed' : 1693,\n",
    "        'estimator_list' : ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', \n",
    "                            'extra_tree', 'kneighbor', 'lrl1', 'lrl2'],\n",
    "        'early_stop' : True,\n",
    "        'verbose' : verbose,\n",
    "        'keep_search_state' : True,\n",
    "        'eval_method' : 'cv'\n",
    "    }\n",
    "    \n",
    "    nonzero_settings = {\n",
    "        'time_budget' : time_budget_mins * 60,  # in seconds\n",
    "        'metric' : nonzero_metric,\n",
    "        'task' : 'regression',\n",
    "        'log_file_name' : os.path.join(base_path, f'nonlinear_hurdle_NONZERO.log'),\n",
    "        'seed' : 1693,\n",
    "        'estimator_list' : ['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'kneighbor'],\n",
    "        'early_stop' : True,\n",
    "        'verbose' : verbose,\n",
    "        'keep_search_state' : True,\n",
    "        'eval_method' : 'cv'\n",
    "    }\n",
    "    \n",
    "    extirp_pos = False\n",
    "    fit_args = {'zero' : zero_settings, 'nonzero' : nonzero_settings}\n",
    "    \n",
    "    #  dumping everything into the hurdle model wrapper\n",
    "    data_args = {'indicator_columns' : indicator_columns,\n",
    "                 'nonzero_columns' : nonzero_columns,\n",
    "                 'zero_columns' : zero_columns,\n",
    "                 'embeddings_to_use' : None,\n",
    "                 'dataset' : dataset}\n",
    "    hurdle_model = HurdleModelEstimator(zero_model, nonzero_model, extirp_pos = extirp_pos, \n",
    "                                        data_args = data_args, verbose = True)\n",
    "\n",
    "    #  defining preprocessing\n",
    "    pp_args = {'include_indicators' : False,\n",
    "               'include_categorical' : False,\n",
    "               'polynomial_features' : 0,\n",
    "               'log_trans_cont' : False,\n",
    "               'dataset' : dataset,\n",
    "               'embeddings_to_use' : None}\n",
    "\n",
    "elif model_to_use == 'dummy_regressor':\n",
    "    strat = 'mean' # either mean or median\n",
    "    model = DummyRegressor(strategy = strat)\n",
    "    \n",
    "    pp_args = {'include_indicators' : False,\n",
    "               'include_categorical' : False,\n",
    "               'polynomial_features' : 0,\n",
    "               'log_trans_cont' : False,\n",
    "               'dataset' : dataset}\n",
    "\n",
    "    #  results saving params\n",
    "    model_name = 'dummy_regressor'\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "90a73cf6-5633-46db-87fc-5c287028aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "data = mammal_data if dataset == 'mammals' else bird_data\n",
    "col = 'Region' if dataset == 'mammals' else 'Realm'\n",
    "resp_col = 'ratio' if dataset == 'mammals' else 'RR'\n",
    "\n",
    "test_idxs = data.index[data[col] == test_region].to_list()\n",
    "train_idxs = [i for i in data.index if i not in test_idxs]\n",
    "idxs = {'train' : train_idxs, 'test' : test_idxs}\n",
    "\n",
    "pp_data = preprocess_data(data, standardize = True, train_test_idxs = idxs, **pp_args)\n",
    "\n",
    "train_data, test_data = pp_data.iloc[idxs['train']], pp_data.iloc[idxs['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6babba6b-2ceb-449b-8172-7c09c1dfb065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "if model_to_use in ['FLAML_hurdle', 'pymer']:\n",
    "    hurdle_model.fit(train_data, fit_args = fit_args)\n",
    "elif model_to_use == 'dummy_regressor':\n",
    "    X_train, y_train = train_data.drop(columns = resp_col), train_data[resp_col]\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14bd6dc7-8086-4bbe-af06-8ae150d62a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the probability threshold for the zero model\n",
    "if model_to_use in ['FLAML_hurdle', 'pymer']:\n",
    "    X_zero, y_zero, _, _ = get_zero_nonzero_datasets(train_data, extirp_pos = hurdle_model.extirp_pos,\n",
    "                                                     pred = False, **hurdle_model.data_args)\n",
    "    y_pred = hurdle_model.zero_model.predict_proba(X_zero)[ : , 1]\n",
    "    \n",
    "    opt_thresh, _ = test_thresholds(y_pred, y_zero)\n",
    "    hurdle_model.prob_thresh = round(opt_thresh, 3)\n",
    "    print(f'Optimal threshold was found to be {hurdle_model.prob_thresh}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3edba21a-6eb6-41ad-a2c7-4341eb14811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: dummy_regressor_SPECIAL_test-region-Africa.csv\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the test set\n",
    "if model_to_use in ['FLAML_hurdle', 'pymer']:\n",
    "    y_pred = hurdle_model.predict(test_data)\n",
    "elif model_to_use == 'dummy_regressor':\n",
    "    X_test = test_data.drop(columns = resp_col)\n",
    "    y_pred = model.predict(X_test)\n",
    "if model_to_use in ['FLAML_hurdle', 'pymer']:\n",
    "    y_pred[y_pred != 0] = np.exp(y_pred[y_pred != 0])\n",
    "\n",
    "y_test = test_data[resp_col].copy(deep = True)\n",
    "\n",
    "#  getting DI categories\n",
    "true_DI_cats = ratios_to_DI_cats(y_test)\n",
    "pred_DI_cats = ratios_to_DI_cats(y_pred)\n",
    "\n",
    "#  saving predictions\n",
    "save_filename = f'{model_name}_SPECIAL_test-region-{test_region.replace(' ', '')}.csv'\n",
    "preds_df = pd.DataFrame({'index' : test_data.index, \n",
    "                         'actual' : y_test,\n",
    "                         'predicted' : y_pred})\n",
    "preds_df = preds_df.set_index('index').sort_index()\n",
    "\n",
    "preds_df.to_csv(os.path.join('..', 'results', 'raw_predictions', save_filename))\n",
    "print(f'Results saved to: {save_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28b54a09-17b0-4ced-8eb1-6622f1eb320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.961\n",
      "MAE (0-1 range): 0.646\n",
      "RMSE: 4.479\n",
      "BA: 0.333\n"
     ]
    }
   ],
   "source": [
    "# Getting performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {round(mae, 3)}')\n",
    "\n",
    "mae_01, _ = mean_absolute_error_range(y_test, y_pred, 0, 1)\n",
    "print(f'MAE (0-1 range): {round(mae_01, 3)}')\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'RMSE: {round(rmse, 3)}')\n",
    "\n",
    "ba = balanced_accuracy_score(true_DI_cats, pred_DI_cats)\n",
    "print(f'BA: {round(ba, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e680ec-310c-48cf-a72c-accb412a6b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
