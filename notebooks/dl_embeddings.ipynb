{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718fd2de-8189-4b58-bcd3-9fa9e4d92fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import open_clip\n",
    "import torch\n",
    "\n",
    "sys.path.append('../satclip')\n",
    "sys.path.append('../satclip/satclip')\n",
    "import satclip\n",
    "from satclip.load import get_satclip\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from utils import get_species_names, format_species_name_CLIP, get_species_embeddings, read_csv_non_utf, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e58280-038d-4b5b-860a-53657c88c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in general configuration\n",
    "with open('../config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Getting filepaths\n",
    "gdrive_fp = config['gdrive_path']\n",
    "LIFE_fp = config['LIFE_folder']\n",
    "dataset_fp = config['datasets_path']\n",
    "\n",
    "# Grabbing Benitez-Lopez\n",
    "benitez_lopez2019 = config['indiv_data_paths']['benitez_lopez2019']\n",
    "ben_lop_path = os.path.join(gdrive_fp, LIFE_fp, dataset_fp, benitez_lopez2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e734c5-d48e-4c70-a380-6f576a3b5bf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Trying out BioCLIP and thinking about integration\n",
    "- Relevant pages for `pytaxize` (to get taxonomic and common names)\n",
    "   - [classifier class - get hierarchy from ID](https://sckott.github.io/pytaxize/modules/classification.html)\n",
    "   - [taxonomic identifier class - get taxonomic ID from scientific name](https://sckott.github.io/pytaxize/modules/ids.html)\n",
    "   - [`taxize` package documentation in R - original package](https://docs.ropensci.org/taxize/articles/taxize.html)\n",
    "- Relevant pages for BioCLIP\n",
    "   - [`open_clip` package documentation - base package](https://pypi.org/project/open-clip-torch/)\n",
    "   - [BioCLIP model page on HuggingFace](https://huggingface.co/imageomics/bioclip) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515f1db4-9a79-478a-8a19-4f3314987928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out on a toy dataset of scientific names\n",
    "sci_names = ['Loxodonta africana', 'Odocoileus virginianus', 'Pandinus imperator']\n",
    "\n",
    "# Reading in the pre-trained BioCLIP model\n",
    "model, _, preprocess_val = open_clip.create_model_and_transforms('hf-hub:imageomics/bioclip')\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:imageomics/bioclip')\n",
    "\n",
    "# Extracting the relevant info from ITIS\n",
    "full_names = []\n",
    "for name in sci_names:\n",
    "    full_names.append(get_species_names(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf73f08-fbe4-4d6a-9746-6048423de683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing with BioCLIP\n",
    "species_embeddings = get_species_embeddings(full_names, model, tokenizer, full_hierarchy = True, common_name = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c84f98-70e1-4526-8475-b634a7a480a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species Loxodonta africana has embedding of shape (512,)\n",
      "['a photo of Animalia Chordata Mammalia Proboscidea Elephantidae Loxodonta africana']\n",
      "\n",
      "Species Odocoileus virginianus has embedding of shape (512,)\n",
      "['a photo of Animalia Chordata Mammalia Artiodactyla Cervidae Odocoileus virginianus']\n",
      "\n",
      "Species Pandinus imperator has embedding of shape (512,)\n",
      "['a photo of Animalia Arthropoda Euchelicerata Scorpiones Scorpionidae Pandinus imperator']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking out the embeddings and the name strings that were processed\n",
    "for k, v in species_embeddings.items():\n",
    "    print(f'Species {k} has embedding of shape {v['embedding'].shape}')\n",
    "    print(v['names_used'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd0b6ee-2bcd-4676-abdb-9528d0eb1beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64558005\n",
      "0.4450716\n"
     ]
    }
   ],
   "source": [
    "# Seeing if elephants are more similar to deer than to scorpions as a basic sanity check\n",
    "print(species_embeddings['Loxodonta africana']['embedding'].dot(species_embeddings['Odocoileus virginianus']['embedding']))\n",
    "print(species_embeddings['Loxodonta africana']['embedding'].dot(species_embeddings['Pandinus imperator']['embedding']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb7134-83ea-4df1-a330-a8884f48c58e",
   "metadata": {},
   "source": [
    "# Trying out SatCLIP for location embeddings\n",
    "\n",
    "It's a little unclear if we want to use the model with $L=50$ or $L=10$; as mentioned in the paper, the latter is better for large-scale patterns and spatial generalization, while the former is better at capturing fine-grained patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d6d7f51-e065-41a2-a9a9-60cf031df582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pretrained moco resnet50\n"
     ]
    }
   ],
   "source": [
    "# Loading a pre-trained SatCLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#  this only loads location encoder by default\n",
    "model = get_satclip(\n",
    "    hf_hub_download(\"microsoft/SatCLIP-ResNet50-L40\", \"satclip-resnet50-l40.ckpt\"),\n",
    "    device = device,\n",
    ")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc52db6a-e656-4e59-938d-6759e84d9b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1213696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out the size of the model - seems relatively small!\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70394230-3540-46ac-8c3a-53740ccf2f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3281, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Benitez-Lopez and extracting coordinates - inputs are (longitude, latitude)\n",
    "ben_lop2019 = read_csv_non_utf(ben_lop_path)\n",
    "coords = torch.from_numpy(ben_lop2019[['X', 'Y']].values).to(device)\n",
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e404e5-32b9-4840-8c47-eab4f05fa50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3281, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing using the pre-trained location embedder from SatCLIP\n",
    "with torch.no_grad():\n",
    "    coord_emb = model(coords).detach().cpu() # these don't seem to be normalized\n",
    "\n",
    "coord_emb.shape # embedding shape is 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bfa2c-d464-4d2c-bd8d-77266ae53f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
